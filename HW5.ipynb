{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA+idiTLTVtatI3pt/uO5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkauffm4/Intro-to-ML/blob/main/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iSG5cQtZEWqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edfd6b7-56d4-4784-dd05-5897e929ac35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w2, w1, b):\n",
        "  return w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "metadata": {
        "id": "CEEudi2mWZ1c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p-t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "eMytZwT3Wme7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [.05, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 50.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "metadata": {
        "id": "2YffgwEVXfEJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2* n_samples)\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]"
      ],
      "metadata": {
        "id": "9gVg7uh4clCp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "  for epoch in range(1, n_epochs +1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    train_t_p = model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad == False\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "            f\" Validation loss {val_loss.item():.4f}\")\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "rSv8X150y1Qb"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = torch.optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(n_epochs = 5000,\n",
        "              optimizer = optimizer,\n",
        "              params = params,\n",
        "              train_t_u = train_t_u,\n",
        "              val_t_u = val_t_u,\n",
        "              train_t_c = train_t_c,\n",
        "              val_t_c = val_t_c\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGAW6tXrA4JB",
        "outputId": "91ca7c80-a9b6-4e8e-d00e-dcaf0eb40407"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Training loss 8.3715, Validation loss 0.7178\n",
            "Epoch 1000, Training loss 5.7811, Validation loss 7.3991\n",
            "Epoch 1500, Training loss 4.4338, Validation loss 21.8965\n",
            "Epoch 2000, Training loss 4.0155, Validation loss 35.2919\n",
            "Epoch 2500, Training loss 3.9306, Validation loss 42.4976\n",
            "Epoch 3000, Training loss 3.9055, Validation loss 44.6940\n",
            "Epoch 3500, Training loss 3.8811, Validation loss 44.7062\n",
            "Epoch 4000, Training loss 3.8509, Validation loss 44.0736\n",
            "Epoch 4500, Training loss 3.8133, Validation loss 43.1975\n",
            "Epoch 5000, Training loss 3.7672, Validation loss 42.1052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0084, -0.2170, -1.6883], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2, Linear Regression model"
      ],
      "metadata": {
        "id": "fBrLrrb6OMzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_model = torch.nn.Linear(5,1) #5 inputs + bias to 1 output linear regression model"
      ],
      "metadata": {
        "id": "WJ9xEAyDOQU_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_training_loop(n_epochs, optimizer, model, loss_fn, train_x, val_x, train_y, val_y):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    pred_y = model(train_x)\n",
        "    train_loss = loss_fn(pred_y, train_y)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_pred_y = model(val_x)\n",
        "      val_loss = loss_fn(val_pred_y, val_y)\n",
        "      assert val_loss.requires_grad == False\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "            f\" Validation loss {val_loss.item():.4f}\")\n",
        "\n",
        "  return model.weight, model.bias"
      ],
      "metadata": {
        "id": "h1yO_0qwO5mX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#varlist = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "def binary_map(x):\n",
        "  return x.map({'yes': 1, 'no': 0})\n",
        "#test = binary_map(varlist)"
      ],
      "metadata": {
        "id": "fv5qc6pARHRA"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "file_path = '/content/drive/My Drive/Intro-to-ML/Housing.csv'\n",
        "sample = pd.DataFrame(pd.read_csv(file_path))\n",
        "varlist = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "sample[varlist] = sample[varlist].apply(binary_map)\n",
        "np.random.seed(0)\n",
        "train_set, test_set = train_test_split(sample, train_size = .8, test_size = .2, random_state = 100)\n",
        "Y = train_set.pop('price')\n",
        "Y_test = test_set.pop('price')\n",
        "junk = train_set.pop('furnishingstatus') #Gotta remove this, its not used\n",
        "junk = test_set.pop('furnishingstatus') #Same with this\n",
        "blerg = train_set\n",
        "train_set_all = train_set.to_numpy()\n",
        "test_set_all = test_set.to_numpy()\n",
        "# Theres a better way to get out the values here, but I don't know it\n",
        "junk = train_set.pop('mainroad')\n",
        "junk = train_set.pop('guestroom')\n",
        "junk = train_set.pop('hotwaterheating')\n",
        "junk = train_set.pop('basement')\n",
        "junk = train_set.pop('airconditioning')\n",
        "junk = train_set.pop('prefarea')\n",
        "junk = test_set.pop('mainroad')\n",
        "junk = test_set.pop('guestroom')\n",
        "junk = test_set.pop('hotwaterheating')\n",
        "junk = test_set.pop('basement')\n",
        "junk = test_set.pop('airconditioning')\n",
        "junk = test_set.pop('prefarea')\n",
        "X_train = train_set.to_numpy()\n",
        "X_test = test_set.to_numpy()\n",
        "Y = Y.to_numpy()\n",
        "Y_test = Y_test.to_numpy()\n",
        "size = len(X_train)\n",
        "x0 = np.ones((size,1))\n",
        "\n",
        "#Dont think this part is needed because the linear model adds bias on its own\n",
        "#X_new_train = np.concatenate((x0,X_train), axis=1)\n",
        "#x0 = np.ones((len(X_test),1))\n",
        "#X_new_test = np.hstack((x0, X_test))"
      ],
      "metadata": {
        "id": "tXt1W4SRQM4N"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize all your stuff\n",
        "X_standard_test = StandardScaler().fit_transform(X_test)\n",
        "X_standard_train = StandardScaler().fit_transform(X_train)\n",
        "train_x = torch.tensor(X_standard_train, dtype=torch.float32)\n",
        "train_y = torch.tensor(Y, dtype=torch.float32)\n",
        "val_x = torch.tensor(X_standard_test, dtype=torch.float32)\n",
        "val_y = torch.tensor(Y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "FAUppMadRVod"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lin_model.parameters(), lr=1e-4)\n",
        "\n",
        "linear_training_loop(n_epochs = 5000,\n",
        "              optimizer = optimizer,\n",
        "              model = lin_model,\n",
        "              loss_fn = loss_fn,\n",
        "              train_x = train_x,\n",
        "              train_y = train_y,\n",
        "              val_x = val_x,\n",
        "              val_y = val_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fko5x60PK1k",
        "outputId": "9f5fb1ec-d826-472d-ed99-e7be527205ab"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Training loss 26477594673152.0000, Validation loss 25158758694912.0000\n",
            "Epoch 1000, Training loss 26477594673152.0000, Validation loss 25158758694912.0000\n",
            "Epoch 1500, Training loss 26477594673152.0000, Validation loss 25158758694912.0000\n",
            "Epoch 2000, Training loss 26477594673152.0000, Validation loss 25158758694912.0000\n",
            "Epoch 2500, Training loss 26477592576000.0000, Validation loss 25158758694912.0000\n",
            "Epoch 3000, Training loss 26477592576000.0000, Validation loss 25158758694912.0000\n",
            "Epoch 3500, Training loss 26477592576000.0000, Validation loss 25158758694912.0000\n",
            "Epoch 4000, Training loss 26477592576000.0000, Validation loss 25158758694912.0000\n",
            "Epoch 4500, Training loss 26477592576000.0000, Validation loss 25158754500608.0000\n",
            "Epoch 5000, Training loss 26477592576000.0000, Validation loss 25158754500608.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[ 0.0204,  0.0910,  0.1928, -0.0199, -0.0062]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.8759], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3"
      ],
      "metadata": {
        "id": "RofHKuFbiFCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_all = torch.tensor(train_set_all, dtype=torch.float32)\n",
        "y_train_all = torch.tensor(Y, dtype=torch.float32)\n",
        "x_test_all = torch.tensor(test_set_all, dtype=torch.float32)\n",
        "y_test_all = torch.tensor(Y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "cfnBrOheoC5y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_model_all = torch.nn.Linear(11,1)"
      ],
      "metadata": {
        "id": "tStmSZgY1Enu"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lin_model_all.parameters(), lr=1e-1)\n",
        "\n",
        "linear_training_loop(n_epochs = 5000,\n",
        "              optimizer = optimizer,\n",
        "              model = lin_model_all,\n",
        "              loss_fn = loss_fn,\n",
        "              train_x = x_train_all,\n",
        "              train_y = y_train_all,\n",
        "              val_x = x_test_all,\n",
        "              val_y = y_test_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPVPq-E-pMhG",
        "outputId": "8b62a3c3-8960-4b48-f847-8ca05879afac"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Training loss 6835577815040.0000, Validation loss 6943963873280.0000\n",
            "Epoch 1000, Training loss 6835048284160.0000, Validation loss 6943445876736.0000\n",
            "Epoch 1500, Training loss 6834518228992.0000, Validation loss 6942926307328.0000\n",
            "Epoch 2000, Training loss 6833988173824.0000, Validation loss 6942407262208.0000\n",
            "Epoch 2500, Training loss 6833459691520.0000, Validation loss 6941891887104.0000\n",
            "Epoch 3000, Training loss 6832929636352.0000, Validation loss 6941371269120.0000\n",
            "Epoch 3500, Training loss 6832399581184.0000, Validation loss 6940850651136.0000\n",
            "Epoch 4000, Training loss 6831869526016.0000, Validation loss 6940338421760.0000\n",
            "Epoch 4500, Training loss 6831339995136.0000, Validation loss 6939815706624.0000\n",
            "Epoch 5000, Training loss 6830811512832.0000, Validation loss 6939289321472.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[ 783.8562, 5906.1865, 5889.3516, 5901.1035, 5877.9204, 5684.1172,\n",
              "          5879.0708, 5904.3730, 5740.9941, 5442.5708, 5459.4810]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([5914.8076], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}